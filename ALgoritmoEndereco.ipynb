{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn7O7Pb/n+MxITbP5hihPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aannddrree/disciplinaIA/blob/main/ALgoritmoEndereco.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcnTgwochF3c",
        "outputId": "6e33f527-f934-4fc7-bf90-872165b6bb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Limiar usado p/ classe positiva: 64.31 (quantil: mediana)\n",
            "[INFO] Distribuição de classes: {1: 5, 0: 5}\n",
            "[Fold 1] AUC=1.0000 | AP=1.0000 | F1=0.4000\n",
            "[WARN] Dobra 2 sem 2 classes em treino ou teste. Pulando.\n",
            "[Fold 3] AUC=0.0000 | AP=0.5000 | F1=0.0000\n",
            "[Fold 4] AUC=0.0000 | AP=0.5000 | F1=0.6667\n",
            "[WARN] Dobra 5 sem 2 classes em treino ou teste. Pulando.\n",
            "[CV] AUC  médio: 0.3333 ± 0.4714\n",
            "[CV] AP   médio: 0.6667 ± 0.2357\n",
            "[CV] F1   médio: 0.3556 ± 0.2740\n",
            "[OK] Modelo salvo em: artefatos_modelo/modelo_logistico_endereco.joblib\n",
            "[OK] Metadata salva em: artefatos_modelo/metadata.json\n",
            "\n",
            "[Ranking de candidatos por probabilidade de 'bom']\n",
            "               endereco_completo         cidade estado      lat      lon  prob_bom\n",
            "Av. Atlântica, 3000, Copacabana Rio de Janeiro     RJ -22.9717 -43.1830  0.631894\n",
            " Av. Paulista, 1000, Bela Vista      Sao Paulo     SP -23.5614 -46.6559  0.505657\n",
            "       Rua Exemplo, 123, Centro      Sao Paulo     SP -23.5440 -46.6330  0.481003\n"
          ]
        }
      ],
      "source": [
        "# arquivo: treino_logistico_enderecos.py\n",
        "# Requisitos (pip):\n",
        "#   pandas scikit-learn joblib numpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score\n",
        "from sklearn.exceptions import UndefinedMetricWarning\n",
        "import warnings\n",
        "import joblib\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
        "\n",
        "# =========================\n",
        "# 1) Carregar dados\n",
        "# =========================\n",
        "CSV_PATH = \"/content/enderecos_com_score.csv\"  # ajuste se necessário\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Checagens básicas\n",
        "required_cols = {\"endereco_completo\", \"cidade\", \"estado\", \"lat\", \"lon\", \"score\"}\n",
        "missing = required_cols - set(df.columns)\n",
        "if missing:\n",
        "    raise ValueError(f\"Colunas faltantes no CSV: {missing}\")\n",
        "\n",
        "# =========================\n",
        "# 2) Criar alvo binário com salvaguardas\n",
        "#    - Garante pelo menos 2 classes\n",
        "#    - Tenta quantis; cai para mediana se necessário\n",
        "#    - Também verifica mínimo de positivos\n",
        "# =========================\n",
        "def make_binary_labels_from_score(scores: pd.Series, prefer_q=0.7, min_pos=10):\n",
        "    qs = [prefer_q, 0.75, 0.8, 0.65, 0.6, 0.55, 0.5, 0.45, 0.4]  # tenta vários quantis\n",
        "    for q in qs:\n",
        "        thr = scores.quantile(q)\n",
        "        y = (scores >= thr).astype(int)\n",
        "        if y.nunique() == 2 and y.sum() >= min_pos:\n",
        "            return y, float(thr), q\n",
        "    # fallback final: mediana\n",
        "    thr = scores.median()\n",
        "    y = (scores >= thr).astype(int)\n",
        "    return y, float(thr), None\n",
        "\n",
        "y, thr, used_q = make_binary_labels_from_score(df[\"score\"])\n",
        "print(f\"[INFO] Limiar usado p/ classe positiva: {thr:.2f} \"\n",
        "      f\"(quantil: {used_q if used_q is not None else 'mediana'})\")\n",
        "print(\"[INFO] Distribuição de classes:\", y.value_counts().to_dict())\n",
        "\n",
        "# =========================\n",
        "# 3) Features e pré-processamento\n",
        "# =========================\n",
        "text_col = \"endereco_completo\"\n",
        "cat_cols  = [\"cidade\", \"estado\"]\n",
        "num_cols  = [\"lat\", \"lon\"]  # adicione outras numéricas se tiver\n",
        "\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"txt\", TfidfVectorizer(max_features=5000, ngram_range=(1, 2)), text_col),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n",
        "        (\"num\", StandardScaler(), num_cols),\n",
        "    ],\n",
        "    remainder=\"drop\",\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "clf = LogisticRegression(\n",
        "    solver=\"lbfgs\",\n",
        "    max_iter=2000,\n",
        "    class_weight=\"balanced\",\n",
        "    n_jobs=None  # remova se sua versão do sklearn não suportar\n",
        ")\n",
        "\n",
        "pipe = Pipeline([(\"prep\", preprocess), (\"clf\", clf)])\n",
        "\n",
        "X = df[[text_col] + cat_cols + num_cols]\n",
        "groups = df[\"cidade\"].astype(str)\n",
        "\n",
        "# =========================\n",
        "# 4) Validação (StratifiedGroupKFold)\n",
        "#    - Estratifica por y, mas respeita grupos (cidade)\n",
        "# =========================\n",
        "n_splits = 5\n",
        "sgkf = StratifiedGroupKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "aucs, aps, f1s = [], [], []\n",
        "split_id = 1\n",
        "for tr_idx, te_idx in sgkf.split(X, y, groups):\n",
        "    X_tr, X_te = X.iloc[tr_idx], X.iloc[te_idx]\n",
        "    y_tr, y_te = y.iloc[tr_idx], y.iloc[te_idx]\n",
        "\n",
        "    # Segurança extra: se por acaso a dobra ainda ficar mono-classe\n",
        "    if y_tr.nunique() < 2 or y_te.nunique() < 2:\n",
        "        print(f\"[WARN] Dobra {split_id} sem 2 classes em treino ou teste. Pulando.\")\n",
        "        split_id += 1\n",
        "        continue\n",
        "\n",
        "    pipe.fit(X_tr, y_tr)\n",
        "    p = pipe.predict_proba(X_te)[:, 1]\n",
        "    yhat = (p >= 0.5).astype(int)\n",
        "\n",
        "    aucs.append(roc_auc_score(y_te, p))\n",
        "    aps.append(average_precision_score(y_te, p))\n",
        "    f1s.append(f1_score(y_te, yhat))\n",
        "    print(f\"[Fold {split_id}] AUC={aucs[-1]:.4f} | AP={aps[-1]:.4f} | F1={f1s[-1]:.4f}\")\n",
        "    split_id += 1\n",
        "\n",
        "if len(aucs) == 0:\n",
        "    raise RuntimeError(\"Todas as dobras foram inválidas (mono-classe). \"\n",
        "                       \"Revise sua base ou a regra de rotulagem.\")\n",
        "\n",
        "print(f\"[CV] AUC  médio: {np.mean(aucs):.4f} ± {np.std(aucs):.4f}\")\n",
        "print(f\"[CV] AP   médio: {np.mean(aps):.4f} ± {np.std(aps):.4f}\")\n",
        "print(f\"[CV] F1   médio: {np.mean(f1s):.4f} ± {np.std(f1s):.4f}\")\n",
        "\n",
        "# =========================\n",
        "# 5) Treino final no dataset completo\n",
        "# =========================\n",
        "pipe.fit(X, y)\n",
        "\n",
        "# =========================\n",
        "# 6) Salvar artefatos do modelo e metadados\n",
        "# =========================\n",
        "OUT_DIR = Path(\"artefatos_modelo\")\n",
        "OUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "joblib.dump(pipe, OUT_DIR / \"modelo_logistico_endereco.joblib\")\n",
        "meta = {\n",
        "    \"threshold\": thr,\n",
        "    \"used_quantile\": used_q,\n",
        "    \"text_col\": text_col,\n",
        "    \"cat_cols\": cat_cols,\n",
        "    \"num_cols\": num_cols,\n",
        "    \"n_splits\": n_splits,\n",
        "    \"cv_auc_mean\": float(np.mean(aucs)),\n",
        "    \"cv_ap_mean\": float(np.mean(aps)),\n",
        "    \"cv_f1_mean\": float(np.mean(f1s)),\n",
        "}\n",
        "pd.Series(meta, dtype=object).to_json(OUT_DIR / \"metadata.json\", force_ascii=False)\n",
        "print(f\"[OK] Modelo salvo em: {OUT_DIR / 'modelo_logistico_endereco.joblib'}\")\n",
        "print(f\"[OK] Metadata salva em: {OUT_DIR / 'metadata.json'}\")\n",
        "\n",
        "# =========================\n",
        "# 7) Exemplo de ranqueamento de candidatos\n",
        "# =========================\n",
        "candidatos = pd.DataFrame([\n",
        "    {\"endereco_completo\": \"Av. Paulista, 1000, Bela Vista\",\n",
        "     \"cidade\": \"Sao Paulo\", \"estado\": \"SP\", \"lat\": -23.5614, \"lon\": -46.6559},\n",
        "    {\"endereco_completo\": \"Rua Exemplo, 123, Centro\",\n",
        "     \"cidade\": \"Sao Paulo\", \"estado\": \"SP\", \"lat\": -23.5440, \"lon\": -46.6330},\n",
        "    {\"endereco_completo\": \"Av. Atlântica, 3000, Copacabana\",\n",
        "     \"cidade\": \"Rio de Janeiro\", \"estado\": \"RJ\", \"lat\": -22.9717, \"lon\": -43.1830},\n",
        "])\n",
        "\n",
        "# Atenção: as colunas dos candidatos devem bater com X (mesmas features)\n",
        "candidatos[\"prob_bom\"] = pipe.predict_proba(candidatos)[:, 1]\n",
        "print(\"\\n[Ranking de candidatos por probabilidade de 'bom']\\n\",\n",
        "      candidatos.sort_values(\"prob_bom\", ascending=False).to_string(index=False))\n"
      ]
    }
  ]
}